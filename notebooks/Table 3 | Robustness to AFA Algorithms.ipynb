{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing broken power law + three parameter power law\n",
    "# Fit the broken power law to this set of values\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sys.path.insert(0, '../../')\n",
    "from curve_models import NLLS_three_param, power_law_three_param, power_law_exp_three_param\n",
    "from curve_models import NLLS_w, power_law\n",
    "from curve_models import BrokenCurve, power_law\n",
    "\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "expmt_dict = {'gl-tiny': '0.1_5_False_uniform_30_0.5_0.5_1880_9400_94001' + '/',\n",
    "                'ml-20m-uniform': '0.1_5_False_uniform_30_0.5_0.5_20000_100000_1000001' + '/', \n",
    "                'ml-20m-tiny':'0.1_5_False_uniform_30_0.5_0.5_5250_21000_213973' + '/',\n",
    "                'gl': '0.1_5_False_uniform_30_0.5_0.5_5800_29000_290001' +'/'}\n",
    "dataset_name = 'g1'\n",
    "afa_algs = ['QBC', 'Weighted']\n",
    "afa_alg_dict = {'QBC': 'QBC', 'Weighted': 'Stability'}\n",
    "dataset_dict =  {'gl':'GoogleLocal-L', 'gl-tiny':'GoogleLocal-S', \n",
    "                 'ml-20m-uniform': 'MovieLens-L', 'ml-20m-tiny': 'MovieLens-S'}\n",
    "\n",
    "# results_dir = \"../../results/forecasting/gl/Random/\"\n",
    "# expmt = \"5_False_0.1_0.4_item_subset_29000_30_4_290001_5800_0_0.5_0.5_0_0.8/\"\n",
    "# expmt = '0.1_3_False_uniform_30_0.5_0.5_1880_9400_94001' + '/'\n",
    "# dataset_name = 'ml-20m-uniform'\n",
    "# expmt = '0.1_5_False_uniform_30_0.5_0.5_20000_100000_1000001' + '/'\n",
    "# dataset_name = 'ml-20m-tiny'\n",
    "# expmt = '0.1_5_False_uniform_30_0.5_0.5_5250_21000_213973' + '/'\n",
    "# dataset_name = 'gl'\n",
    "# expmt = '0.1_5_False_uniform_30_0.5_0.5_5800_29000_290001' +'/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot true slope\n",
    "n_runs = 5\n",
    "slope_dicts = []\n",
    "hue_order = ['True', 'NLS_initial', 'NLS_w', 'NLS_power_law_3P', 'NLS_power_law_exp_3P', 'broken', \n",
    "             'Naive']\n",
    "for afa_alg in afa_algs:\n",
    "    print(dataset_name, expmt_dict)\n",
    "    expmt = expmt_dict['gl']\n",
    "    results_dir = \"../../results/forecasting/\" + dataset_name + \"/\" + afa_alg + \"/\"\n",
    "    results_path = results_dir + expmt\n",
    "\n",
    "    all_ss = np.loadtxt(results_path + 'sample_sizes')\n",
    "    all_mses = np.loadtxt(results_path + 'mses')\n",
    "    # Simulate a larger step size\n",
    "    all_ss = all_ss[:,::2]\n",
    "    all_mses = all_mses[:,::2]\n",
    "    data = pd.read_csv(results_path + 'results_df')\n",
    "    n_init = data['n_init'].iloc[0]\n",
    "    n_max = all_ss[0][-1]\n",
    "    for r in range(n_runs):\n",
    "        ss = all_ss[r]\n",
    "        mses = all_mses[r]\n",
    "        for i in range(1, len(ss)-1):\n",
    "            if ss[i] < n_init:\n",
    "                continue\n",
    "            pct = ss[i]/n_max\n",
    "            # slope between i-1 and i \n",
    "            # slope between i and i+1\n",
    "            slope_before = (mses[i] - mses[i-1])/(ss[i] - ss[i-1])\n",
    "            slope_after = (mses[i+1] - mses[i])/(ss[i+1] - ss[i])\n",
    "            slope = .5*(slope_before+slope_after)\n",
    "            slope_dicts.append({'size': ss[i], 'slope': slope, 'run': r, 'cm': 'True',\n",
    "                               'dataset': dataset_name, 'afa_alg': afa_alg, 'pct': pct})\n",
    "            \n",
    "            slope = (mses[i] - mses[i-1])/(ss[i] - ss[i-1])\n",
    "            slope_dicts.append({'size': ss[i], 'slope': slope, 'run': r, 'cm': 'Naive',\n",
    "                               'dataset': dataset_name, 'pct': pct, 'afa_alg': afa_alg})\n",
    "\n",
    "            nlls = NLLS_w(power_law)\n",
    "            stop_pt = min(np.where(ss > n_init)[0])\n",
    "            nlls.fit(ss[:stop_pt], mses[:stop_pt])\n",
    "            slope = nlls.slope(ss[i])\n",
    "            slope_dicts.append({'size': ss[i], 'slope': slope, 'run': r, 'cm': 'NLS_initial',\n",
    "                               'dataset': dataset_name, 'afa_alg': afa_alg, 'pct': pct})\n",
    "\n",
    "            nlls_w = NLLS_w(power_law)\n",
    "            nlls_w.fit(ss[:i+1], mses[:i+1])\n",
    "            slope = nlls_w.slope(ss[i])\n",
    "            slope_dicts.append({'size': ss[i], 'slope': slope, 'run': r, 'cm': 'NLS_w',\n",
    "                               'dataset': dataset_name, 'afa_alg': afa_alg, 'pct': pct})\n",
    "\n",
    "            nlls_3p = NLLS_three_param(power_law_three_param, \"power_law_3p\")\n",
    "            nlls_3p.fit(ss[:i+1], mses[:i+1]) \n",
    "            slope = nlls_3p.slope(ss[i])\n",
    "            slope_dicts.append({'size': ss[i], 'slope': slope, 'run': r, 'cm': 'NLS_power_law_3P',\n",
    "                               'dataset': dataset_name, 'afa_alg': afa_alg, 'pct': pct})\n",
    "\n",
    "            nlls_3p = NLLS_three_param(power_law_three_param, \"power_law_3p\")\n",
    "            nlls_3p.fit(ss[:i+1], mses[:i+1]) \n",
    "            slope = nlls_3p.slope(ss[i])\n",
    "            slope_dicts.append({'size': ss[i], 'slope': slope, 'run': r, 'cm': 'NLS_power_law_3P',\n",
    "                               'dataset': dataset_name, 'afa_alg': afa_alg, 'pct': pct})\n",
    "\n",
    "            nlls_exp_3p = NLLS_three_param(power_law_exp_three_param, \"power_law_exp_3p\")\n",
    "            nlls_exp_3p.fit(ss[:i+1], mses[:i+1])\n",
    "            slope = nlls_exp_3p.slope(ss[i])\n",
    "            slope_dicts.append({'size': ss[i], 'slope': slope, 'run': r, 'cm': 'NLS_power_law_exp_3P', \n",
    "                               'dataset': dataset_name, 'afa_alg': afa_alg, 'pct': pct})\n",
    "\n",
    "            broken = BrokenCurve(power_law, \"3p-power-law\")\n",
    "            broken.fit(ss[:i+1], mses[:i+1])\n",
    "            slope = broken.slope(ss[i])\n",
    "            slope_dicts.append({'size': ss[i], 'slope': slope, 'run': r, 'cm': 'broken',\n",
    "                                'dataset': dataset_name, 'afa_alg': afa_alg, 'pct': pct})\n",
    "\n",
    "slope_df = pd.DataFrame(slope_dicts)\n",
    "slope_df.to_csv('../../results/slopes_gl_afa_algs_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df = pd.read_csv('../../results/slopes_gl_afa_algs_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_order = ['True', 'NLS_initial', 'NLS_w', 'NLS_power_law_3P', 'NLS_power_law_exp_3P', 'Naive',\n",
    "             'broken']\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "colors = sns.color_palette(\"colorblind\")\n",
    "sns.set_palette([colors[3], colors[1], colors[0], colors[8], colors[9], colors[2]])\n",
    "dataset_titles = {'gl': 'GoogleLocal-L', 'gl-tiny': 'GoogleLocal-S', 'ml-20m-tiny': 'MovieLens-S',\n",
    "                 'ml-20m-uniform': 'MovieLens-L'}\n",
    "all_data_dfs  = []\n",
    "for i,afa_alg in enumerate(afa_algs):\n",
    "    ax = axs[i]\n",
    "    data_df = slope_df[slope_df['afa_alg'] == afa_alg]\n",
    "    sns.lineplot(x='pct', y='slope', hue='cm', hue_order=hue_order, data=data_df, \n",
    "                ax = ax)\n",
    "    ax.set_xlabel(\"% of Available Data\")\n",
    "    ax.set_title(dataset_titles[dataset_name])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Slope (Return in MSE \\n for each Additional Feature-Value)\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    if i != 3:\n",
    "        ax.get_legend().remove()\n",
    "    else:\n",
    "        L=ax.get_legend()\n",
    "        new_names = ['Curve Model', 'True', '2P-Power-Law-Initial', '2P-Power-Law', '3P-Power-Law', \n",
    "                     '3P-Power-Law-Exp-Cutoff', 'Ours']\n",
    "        for i,new in enumerate(new_names):\n",
    "            L.get_texts()[i].set_text(new)\n",
    "    all_data_dfs.append(data_df)\n",
    "plt.tight_layout()\n",
    "\n",
    "all_data_df = pd.concat(all_data_dfs)\n",
    "\n",
    "suptitle = plt.suptitle(\"Minimizing by Diminishing Returns: Prediction of Returns on Data\", y=1.02)\n",
    "plt.savefig(\"../../figs/diminishing_returns_fig\", bbox_inches='tight',bbox_extra_artists=[suptitle])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(slope_df[slope_df['afa_alg'] == afa_alg]['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['t', 'NLS_initial',  'NLS_w', 'NLS_power_law_3P', 'NLS_power_law_exp_3P', 'broken', \n",
    "        'Naive', 'True']\n",
    "methods = ['NLS_initial',  'NLS_w', 'NLS_power_law_3P', 'NLS_power_law_exp_3P', 'broken', \n",
    "           'Naive', 'True']\n",
    "final_tables = []\n",
    "all_data_df = slope_df\n",
    "for afa_alg in afa_algs:\n",
    "    # pcts collected for different thresholds\n",
    "    thresholds = [-5e-7, -2e-7, -1e-7]\n",
    "    threshold_tables = []\n",
    "    for t in thresholds: \n",
    "        dataset_df = all_data_df[all_data_df['afa_alg'] == afa_alg]\n",
    "        thresh_df = dataset_df[dataset_df['slope'] > t]\n",
    "        t_df = thresh_df.groupby(['run', 'cm']).first().reset_index()\n",
    "        t_df['t'] = t\n",
    "        t_df['afa_alg'] = afa_alg\n",
    "        threshold_tables.append(t_df)\n",
    "    threshold_table_df = pd.concat(threshold_tables)\n",
    "    print(set(threshold_table_df['cm']))\n",
    "    # create table of means + stds over runs\n",
    "    table_df = threshold_table_df.pivot(index=['t', 'run'], columns='cm', values='pct').reset_index()\n",
    "    table_df = table_df.fillna(1)\n",
    "    print(table_df.keys())\n",
    "    table_df_means = table_df.groupby(['t']).mean().reset_index()\n",
    "    table_df_stds = table_df.groupby(['t']).std().reset_index()\n",
    "    for col in methods:\n",
    "        table_df_means.rename(columns={col: col+'|mean'}, inplace=True)\n",
    "        table_df_stds.rename(columns={col: col+'|std'}, inplace=True)\n",
    "    table_df_means = table_df_means.reset_index()\n",
    "    table_df_stds = table_df_stds.reset_index()\n",
    "    table_df_means_stds = table_df_means.merge(table_df_stds, on='t')\n",
    "\n",
    "    # turn into latex-ready table with strings\n",
    "    for method in methods:\n",
    "        mean_key = method + '|mean'\n",
    "        std_key = method + '|std'    \n",
    "        mean_values = table_df_means_stds[mean_key].round(4).map('{:.2f}'.format)\n",
    "        std_values = table_df_means_stds[std_key].round(4).map('{:.2f}'.format)\n",
    "        table_df_means_stds[method] = '$' + mean_values +  ' ± ' + std_values + \"$\"\n",
    "    final_table = table_df_means_stds[cols]\n",
    "    \n",
    "    # Clean up column names\n",
    "    final_table_col_dict = {'t': 'Threshold', 'NLS_initial': '2P-PL-Initial',  'NLS_w': '2P-PL', 'NLS_power_law_3P': '3P-PL', \n",
    "                   'NLS_power_law_exp_3P': '3P-PL-Exp', 'broken': 'Ours', \n",
    "                            'True': 'True', 'Naive': 'Naive'}\n",
    "    final_table.rename(columns=final_table_col_dict, inplace=True)\n",
    "    final_table['Dataset'] = dataset_name\n",
    "    final_table['AFA Alg'] = afa_alg_dict[afa_alg]\n",
    "    final_tables.append(final_table)\n",
    "final_tables_df = pd.concat(final_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_e_notation(input_str):\n",
    "    if '.' not in input_str:\n",
    "        input_str =  input_str[:2] + '.0' + input_str[2:]\n",
    "    return input_str\n",
    "final_tables_df['Threshold'] = final_tables_df['Threshold'].astype(str).apply(rewrite_e_notation)\n",
    "final_col_order = ['AFA Alg', 'Threshold', '2P-PL-Initial',   '2P-PL', \n",
    "                   '3P-PL', '3P-PL-Exp', 'Naive', 'Ours', 'True']\n",
    "final_tables_df = final_tables_df[final_col_order]\n",
    "latex_string = final_tables_df.to_latex(escape=False,  index=False,\n",
    "                                        column_format='l|c|ccccccc')\n",
    "latex_string = latex_string.replace('±','\\pm')\n",
    "print(latex_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single threshold figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_preds = []\n",
    "for run in [2]:\n",
    "    best_preds.append([])\n",
    "    for n_obs in list(np.arange(10,30)):\n",
    "        ss = all_ss[run]\n",
    "        mses = all_mses[run]\n",
    "        #nlls_3p = BrokenCurve(power_law, \"power_law_exp\")\n",
    "        nlls_3p = NLLS_three_param(power_law_three_param, \"3p-power-law\")\n",
    "        #nlls_3p = BrokenCurve(power_law, \"broken_power_law\")\n",
    "        nlls_3p.fit(ss[:n_obs], mses[:n_obs])\n",
    "\n",
    "        # print(nlls_3p.p)\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(ss, mses, label='True')\n",
    "        preds = [nlls_3p.pred(i) for i in ss]\n",
    "        plt.plot(ss, preds, label='Preds')\n",
    "        plt.legend()\n",
    "        slopes.append(nlls_3p.slope())\n",
    "#         best_preds[run].append(preds[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Significance Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_table_dfs  = []\n",
    "dataset_names = ['gl']\n",
    "for dataset in dataset_names:\n",
    "    # pcts collected for different thresholds\n",
    "    thresholds = [-.5e-6, -.4e-6, -.3e-6, -.25e-6, -.2e-6, -.15e-6,-.1e-6,-.05e-6]\n",
    "    threshold_tables = []\n",
    "    for t in thresholds: \n",
    "        dataset_df = all_data_df[all_data_df['dataset'] == dataset]\n",
    "        thresh_df = dataset_df[dataset_df['slope'] > t]\n",
    "        t_df = thresh_df.groupby(['run', 'cm']).first().reset_index()\n",
    "        t_df['t'] = t\n",
    "        t_df['dataset'] = dataset\n",
    "        threshold_tables.append(t_df)\n",
    "    threshold_table_df = pd.concat(threshold_tables)\n",
    "    threshold_table_dfs.append(threshold_table_df)\n",
    "threshold_table_dfs = pd.concat(threshold_table_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "dataset = 'gl'\n",
    "dataset_threshold_df = threshold_table_dfs[threshold_table_dfs['dataset'] == dataset]\n",
    "print(len(dataset_threshold_df))\n",
    "\n",
    "dataset_threshold_df = dataset_threshold_df.pivot(index=['t', 'run'], columns='cm', values='pct').reset_index()\n",
    "print(len(dataset_threshold_df))\n",
    "dataset_threshold_df.fillna(1, inplace=True)\n",
    "baselines = ['NLS_initial', 'NLS_power_law_3P', 'NLS_w', 'NLS_power_law_exp_3P', 'Naive']\n",
    "for baseline in baselines:\n",
    "    our_error = np.abs(dataset_threshold_df['broken'] - dataset_threshold_df['True'])\n",
    "    baseline_error = np.abs(dataset_threshold_df[baseline] - dataset_threshold_df['True'])\n",
    "    print(baseline, ttest_ind(our_error, baseline_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.power_law.alpha)\n",
    "print(results.power_law.xmin)\n",
    "R, p = results.distribution_compare('power_law', 'lognormal', normalized_ratio=True)\n",
    "print(R, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lognormal and exponential make more sense?\n",
    "# could turn this into a prob dist so that it's actually describing the shape \n",
    "\n",
    "freqs = 100000* all_mses[1]/np.sum(all_mses[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [int(f) for f in freqs]\n",
    "\n",
    "all_samples = []\n",
    "for i,ss in enumerate(all_ss[1]):\n",
    "    all_samples.extend([ss for j in range(freqs[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = powerlaw.Fit(all_samples[:60000])\n",
    "print(results.power_law.alpha)\n",
    "print(results.power_law.xmin)\n",
    "R, p = results.distribution_compare('power_law', 'exponential', normalized_ratio=True)\n",
    "print(R, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
