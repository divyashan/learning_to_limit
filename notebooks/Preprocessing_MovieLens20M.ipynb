{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def filter_by_freq(df: pd.DataFrame, column: str, min_freq: int) -> pd.DataFrame:\n",
    "    freq = df[column].value_counts()\n",
    "    frequent_values = freq[freq > min_freq].index\n",
    "    return df[df[column].isin(frequent_values)]\n",
    "def create_id_map(sampled_ids):\n",
    "    sampled_ids = sorted(sampled_ids)\n",
    "    id_map = {x:i for i,x in enumerate(sampled_ids)}\n",
    "    return id_map\n",
    "def print_sample_summary(df, user_col_name='userId', item_col_name='movieId'):\n",
    "    n_unique_users = len(set(df[user_col_name]))\n",
    "    n_unique_items = len(set(df[item_col_name]))\n",
    "    n_ratings = len(df)\n",
    "    print(n_ratings, \" ratings, \", n_unique_users, \" users, \", n_unique_items, \" items\")\n",
    "    print(\"Sparsity: \", n_ratings/(n_unique_users*n_unique_items))\n",
    "\n",
    "# Getting all data\n",
    "users = pd.read_csv('../datasets/ml-20m/ratings.csv')\n",
    "print_sample_summary(users)\n",
    "n_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out users with <100 ratings --> 51869 users , 26654 items\n",
    "# Sampling 5000 users from this set randomly\n",
    "filtered_users = filter_by_freq(users, 'userId', 100)\n",
    "userIds = list(set(filtered_users['userId'].to_list()))\n",
    "sampled_users = np.random.choice(userIds, 5000, replace=False)\n",
    "f_s_users = filtered_users[filtered_users['userId'].isin(sampled_users)]\n",
    "sampled_uids = list(set(f_s_users['userId']))\n",
    "sampled_mids = list(set(f_s_users['movieId']))\n",
    "print_sample_summary(f_s_users)\n",
    "\n",
    "# save this to diff splits in the datasets directory...\n",
    "sampled_uids = list(set(f_s_users['userId']))\n",
    "sampled_mids = list(set(f_s_users['movieId']))\n",
    "\n",
    "uid_map = create_id_map(sampled_uids)\n",
    "mid_map = create_id_map(sampled_mids)\n",
    "f_s_users['uid'] = f_s_users['userId'].map(uid_map)\n",
    "f_s_users['mid'] = f_s_users['movieId'].map(mid_map)\n",
    "f_s_users.to_csv('../datasets/ml-20m-uniform/u.data')\n",
    "\n",
    "\n",
    "for i in range(n_runs):\n",
    "    X = f_s_users.copy()\n",
    "    X = X.sample(frac=1)\n",
    "    uids = X.pop('uid').to_frame()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, uids,stratify=uids, test_size=0.2)\n",
    "    X_train['uid'] = y_train.values.squeeze()\n",
    "    X_test['uid'] = y_test.values.squeeze()\n",
    "    X_train.to_csv('../datasets/ml-20m-uniform/u' + str(i) + '.base')\n",
    "    X_test.to_csv('../datasets/ml-20m-uniform/u' + str(i) + '.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create very small dataset (100 users)\n",
    "\n",
    "# Sampling dataset\n",
    "sampled_users = np.random.choice(userIds, 1000, replace=False)\n",
    "tiny_sampled_users = filtered_users[filtered_users['userId'].isin(sampled_users)]\n",
    "print_sample_summary(tiny_sampled_users)\n",
    "\n",
    "# Saving splits\n",
    "sampled_uids = list(set(tiny_sampled_users['userId']))\n",
    "sampled_mids = list(set(tiny_sampled_users['movieId']))\n",
    "uid_map = create_id_map(sampled_uids)\n",
    "mid_map = create_id_map(sampled_mids)\n",
    "tiny_sampled_users['uid'] = tiny_sampled_users['userId'].map(uid_map)\n",
    "tiny_sampled_users['mid'] = tiny_sampled_users['movieId'].map(mid_map)\n",
    "tiny_sampled_users.to_csv('../datasets/ml-20m-tiny/u.data')\n",
    "\n",
    "for i in range(n_runs):\n",
    "    X = tiny_sampled_users.copy()\n",
    "    X = X.sample(frac=1)\n",
    "    uids = X.copy().pop('uid').to_frame()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, uids,stratify=uids, test_size=0.2)\n",
    "    X_train['uid'] = y_train.values.squeeze()\n",
    "    X_test['uid'] = y_test.values.squeeze()\n",
    "    X_train.to_csv('../datasets/ml-20m-tiny/u' + str(i) + '.base')\n",
    "    X_test.to_csv('../datasets/ml-20m-tiny/u' + str(i) + '.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ml-20m-tiny'\n",
    "split_num = 0\n",
    "ratings = pd.read_csv('../datasets/' + dataset_name + '/u.data') \n",
    "ratings_matrix = ratings.pivot_table(index=['uid'],columns=['mid'],values='rating').reset_index(drop=True)\n",
    "ratings_matrix.fillna(0, inplace = True)\n",
    "data_matrix = np.array(ratings_matrix)\n",
    "\n",
    "tr_ratings = pd.read_csv('../datasets/' + dataset_name + '/u' + str(split_num) + '.base')\n",
    "test_ratings = pd.read_csv('../datasets/' + dataset_name + '/u' + str(split_num) + '.test')\n",
    "train_idxs = tr_ratings[['uid', 'mid']].values \n",
    "test_idxs = test_ratings[['uid', 'mid']].values \n",
    "train_idxs = list(map(tuple, train_idxs))\n",
    "test_idxs = list(map(tuple, test_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[ratings['uid'] == 50].head(), tr_ratings[tr_ratings['uid'] == 50].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the 6000 users and 4000 movies with the highest # of ratings\n",
    "sampled_uids = users['userId'].value_counts()[:6000].index.to_list()\n",
    "sampled_mids = users['movieId'].value_counts()[:4000].index.to_list()\n",
    "sampled_ratings  = users[users['userId'].isin(sampled_uids) & users['movieId'].isin(sampled_mids)]\n",
    "sampled_ratings.to_csv('../datasets/ml-20m/u.data')\n",
    "len(set(sampled_ratings['userId'])), len(set(sampled_ratings['movieId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_map = create_id_map(sampled_uids)\n",
    "mid_map = create_id_map(sampled_mids)\n",
    "sampled_ratings['uid'] = sampled_ratings['userId'].map(uid_map)\n",
    "sampled_ratings['mid'] = sampled_ratings['movieId'].map(mid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings = len(sampled_ratings)\n",
    "# save sampled_ratings to u.data\n",
    "n_runs = 10\n",
    "uids = sampled_ratings.copy().pop('uid').to_frame()\n",
    "X = sampled_ratings\n",
    "for i in range(n_runs):\n",
    "    X = X.sample(frac=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, uids,stratify=uids, test_size=0.2)\n",
    "    X_train['uid'] = y_train.values.squeeze()\n",
    "    X_test['uid'] = y_test.values.squeeze()\n",
    "    X_train.to_csv('../datasets/ml-20m/u' + str(i) + '.base')\n",
    "    X_test.to_csv('../datasets/ml-20m/u' + str(i) + '.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(3, 3, figsize=(8, 10), sharey=True)\n",
    "pct_opts = [(.25, \"25\"), (.50, \"50\"), (.75, \"75\")]\n",
    "init_modes = ['uniform', 'user_subset', 'item_subset']\n",
    "for i, init_mode in enumerate(init_modes):\n",
    "    expmt = '5_False_0.1_0.4_' + init_mode + '_21000_5250_0_30_1_213973_0.5_0.5_0_0.85'\n",
    "    data = pd.concat([pd.read_csv('../results/ml-20m-tiny/Weighted/' + expmt + '/results_df'),\n",
    "                      pd.read_csv('../results/ml-20m-tiny/Random/' + expmt + '/results_df'),\n",
    "                      pd.read_csv('../results/ml-20m-tiny/QBC/' + expmt + '/results_df')])\n",
    "    for j, pct_opt in enumerate(pct_opts):\n",
    "        pct_available, pct_str = pct_opt        \n",
    "        data_one_m = data[(data['pct_available'] > pct_available - .05) & (data['pct_available'] < pct_available + .05)]\n",
    "        sns.boxplot(x='acq_model', y='micro_mse',  data=data_one_m, ax=ax[i][j], order=['Random', 'QBC', 'Weighted'])\n",
    "       ##ax[i][j].set_yticks([2600, 2800, 3000])\n",
    "\n",
    "        if i == 0:\n",
    "            ax[i][j].set_title(pct_str + \"% Data\")\n",
    "\n",
    "        if i == 2:\n",
    "            ax[i][j].set_xlabel(\"Acquisition model\")\n",
    "        else:\n",
    "            ax[i][j].set_xlabel(\"\")\n",
    "            ax[i][j].set_xticks([])\n",
    "        if j == 0:\n",
    "            ax[i][j].set_ylabel(\"MSE\")\n",
    "            #ax[i][j].set_yticks([.25, .50, .75])\n",
    "            #ax[i][j].set_yticks([7300, 7750, 8200])\n",
    "        else:\n",
    "#             ax[i][j].set_yticks([])\n",
    "            ax[i][j].set_ylabel(\"\")\n",
    "        ax[i][j].set_xticklabels(['Random', 'Stability', 'QBC'], rotation=45)\n",
    "\n",
    "        #ax[i][j].set_ylim(2500, 3050)\n",
    "plt.suptitle(\"AFA Performance across initializations\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_available = .5\n",
    "init_mode = 'user_subset'\n",
    "expmt = '20000_0.1_1_0.5_0.5_' + init_mode + '_uniform_0.0_30_False_1000_5'\n",
    "data = pd.concat([pd.read_csv('./results/ml-20m-tiny/Weighted/' + expmt + '/results_df'),\n",
    "                  pd.read_csv('./results/ml-20m-tiny/Random/' + expmt + '/results_df'),\n",
    "                  pd.read_csv('./results/ml-20m-tiny/QBC/' + expmt + '/results_df')])\n",
    "data[(data['pct_available'] > pct_available - .02) & (data['pct_available'] < pct_available + .02)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='acq_model', y='micro_mse', data=data_one_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
